{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import simplejson as json\n",
    "import itertools\n",
    "from functools import cmp_to_key\n",
    "import networkx as nx\n",
    "\n",
    "from IPython.display import display, Image, JSON\n",
    "from ipywidgets import widgets, Image, HBox, VBox, Button, ButtonStyle, Layout, Box\n",
    "\n",
    "from lib.image_dedup import make_hashes, calculate_distance, hashes_diff\n",
    "from lib.PersistentSet import PersistentSet\n",
    "from lib.sort_things import post_score, sort_posts, sort_images\n",
    "from lib.parallel import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = Path('../images')\n",
    "handmade_dir = Path('./handmade')\n",
    "handmade_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_uri = json.load(open('./credentials/mongodb_credentials.json'))['uri']\n",
    "mongo = MongoClient(mongo_uri)\n",
    "db = mongo['bad-vis']\n",
    "posts = db['posts']\n",
    "imagefiles = db['imagefiles']\n",
    "imagemeta = db['imagemeta']\n",
    "imagededup = db['imagededup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagededup.drop()\n",
    "for i in imagemeta.find():\n",
    "    imagededup.insert_one(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDedup = [m for m in imagemeta.find()]\n",
    "imageDedup.sort(key=lambda x: x['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phash_to_idx_mapping = {}\n",
    "for i in range(len(imageDedup)):\n",
    "    phash = imageDedup[i]['phash']\n",
    "    l = phash_to_idx_mapping.get(phash, [])\n",
    "    l.append(i)\n",
    "    phash_to_idx_mapping[phash] = l\n",
    "def phash_to_idx (phash):\n",
    "    return phash_to_idx_mapping.get(phash, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_to_idx_mapping = {imageDedup[i]['image_id']:i for i in range(len(imageDedup))}\n",
    "def image_id_to_idx (image_id):\n",
    "    return image_id_to_idx_mapping.get(image_id, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_hashes = [make_hashes(m) for m in imageDedup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa8f9bf40304bb893fdff325f7dfc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2601.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7250fb207a73448ab511b267c62c69bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10449.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# distance = calculate_distance(image_hashes)\n",
    "distance = calculate_distance(image_hashes, hash_type='phash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance2 = np.ndarray([len(image_hashes), len(image_hashes)])\n",
    "# for i in tqdm(range(len(image_hashes))):\n",
    "#     for j in range(i+1):\n",
    "#         diff = hashes_diff(image_hashes[i], image_hashes[j])\n",
    "#         distance2[i, j] = diff\n",
    "#         distance2[j, i] = diff\n",
    "# np.array_equal(distance, distance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdistance = calculate_distance(image_hashes, hash_type='phash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find duplicated pairs from distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_distance (hashes, value, mat=distance):\n",
    "    phash_x = hashes[0]\n",
    "    phash_y = phash_x if len(hashes) == 1 else hashes[1]\n",
    "    idx_x = phash_to_idx(phash_x)\n",
    "    idx_y = phash_to_idx(phash_y)\n",
    "    if idx_x == None or idx_y == None:\n",
    "        return\n",
    "    for s in itertools.product(idx_x, idx_y):\n",
    "        i, j = s\n",
    "        mat[i, j] = value\n",
    "        mat[j, i] = value\n",
    "\n",
    "def set_distance_pairs (phash_pairs, value, mat=distance):\n",
    "    for p in phash_pairs:\n",
    "        set_distance(list(p), value, mat=mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_duplicated_image_phash_pairs = PersistentSet()\n",
    "auto_duplicated_image_phash_pairs.set_file(handmade_dir/'auto_duplicated_image_phash_pairs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d67d48a6574fecb2e80a8b3cf9739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10449.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(distance.shape[0])):\n",
    "    for j in range(i):\n",
    "        if distance[i, j] <= 1: # checked, all distance <= 1 are duplicated\n",
    "            auto_duplicated_image_phash_pairs.add(frozenset([imageDedup[i]['phash'], imageDedup[j]['phash']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(pdistance.shape[0])):\n",
    "#     for j in range(i):\n",
    "#         if pdistance[i, j] <= 1: # checked, all distance <= 1 are duplicated\n",
    "#             auto_duplicated_image_phash_pairs.add(frozenset([imageDedup[i]['phash'], imageDedup[j]['phash']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_duplicated_image_phash_pairs.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply information from meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91afc3ae4a874978abc27b14e64f7ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "duplicated_post_image_phash_pairs = PersistentSet()\n",
    "duplicated_post_image_phash_pairs.set_file(handmade_dir/'duplicated_post_image_phash_pairs.json')\n",
    "\n",
    "for p in tqdm(posts.find()):\n",
    "    if len(p.get('duplicated_posts', [])) == 0:\n",
    "        continue\n",
    "\n",
    "    dp_phashes = {i['phash']\n",
    "                    for dp in p['duplicated_posts']\n",
    "                    for i in imagemeta.find({'post_id': dp})}\n",
    "    if len(dp_phashes) > 1:\n",
    "#         print(f\"More than 1 dp image {p['post_id']}\")\n",
    "#         print(f\"{p['duplicated_posts']} {dp_phashes}\")\n",
    "        continue\n",
    "\n",
    "    phashes = [i['phash'] for i in imagemeta.find({'post_id': p['post_id']})]\n",
    "    if len(phashes) > 1:\n",
    "#         print(f\"More than 1 image {p['post_id']} {phashes}\")\n",
    "        continue\n",
    "    for s in itertools.product(dp_phashes, phashes):\n",
    "        fs = frozenset(s)\n",
    "        if len(fs) > 1:\n",
    "            duplicated_post_image_phash_pairs.add(fs)\n",
    "\n",
    "duplicated_post_image_phash_pairs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7532113a5ae94d35ba05a3d585cbcaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 or less image 2ophbe ['8c7233d364cc6673']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "related_album_image_phash_pairs = PersistentSet()\n",
    "related_album_image_phash_pairs.set_file(handmade_dir/'related_album_image_phash_pairs.json')\n",
    "\n",
    "for album in tqdm({i['album'] for i in imagemeta.find({'album': {'$exists': True, '$ne': ''}})}):\n",
    "    ra_phashes = [i['phash'] for i in imagemeta.find({'album': album})]\n",
    "    if len(ra_phashes) <= 1:\n",
    "        print(f\"Only 1 or less image {album} {ra_phashes}\")\n",
    "\n",
    "    for s in itertools.product(ra_phashes, ra_phashes):\n",
    "        fs = frozenset(s)\n",
    "        if len(fs) > 1:\n",
    "            related_album_image_phash_pairs.add(fs)\n",
    "\n",
    "related_album_image_phash_pairs.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply manual labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_image_phash_pairs = PersistentSet.load_set(handmade_dir/'duplicated_image_phash_pairs.json')\n",
    "not_duplicated_image_phash_pairs = PersistentSet.load_set(handmade_dir/'not_duplicated_image_phash_pairs.json')\n",
    "related_image_phash_pairs = PersistentSet.load_set(handmade_dir/'related_image_phash_pairs.json')\n",
    "invalid_image_phashes = PersistentSet.load_set(handmade_dir/'invalid_image_phashes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_distance_pairs(auto_duplicated_image_phash_pairs, 0)\n",
    "set_distance_pairs(duplicated_post_image_phash_pairs, 0)\n",
    "set_distance_pairs(duplicated_image_phash_pairs, 0)\n",
    "set_distance_pairs(not_duplicated_image_phash_pairs, 60)\n",
    "set_distance_pairs(related_album_image_phash_pairs, 60)\n",
    "set_distance_pairs(related_image_phash_pairs, 60)\n",
    "\n",
    "related_distance = np.full(distance.shape, 60)\n",
    "set_distance_pairs(related_album_image_phash_pairs, 0, mat=related_distance)\n",
    "set_distance_pairs(related_image_phash_pairs, 0, mat=related_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dedup_box (idx_x, idx_y, default=None):\n",
    "    image_x = imageDedup[idx_x]\n",
    "    phash_x = image_x['phash']\n",
    "    image_y = imageDedup[idx_y]\n",
    "    phash_y = image_y['phash']\n",
    "    hash_pair = frozenset([phash_x, phash_y])\n",
    "\n",
    "    yes_btn = widgets.Button(description=\"Duplicated\", button_style='success')\n",
    "    no_btn = widgets.Button(description=\"Not\", button_style='info')\n",
    "    related_btn = widgets.Button(description=\"Related\", button_style='warning')\n",
    "    invalid_x_btn = widgets.Button(description=\"X Invalid\")\n",
    "    invalid_y_btn = widgets.Button(description=\"Y Invalid\")\n",
    "    reset_btn = widgets.Button(description=\"Reset\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_yes (btn):\n",
    "        with output:\n",
    "            if hash_pair in not_duplicated_image_phash_pairs:\n",
    "                not_duplicated_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Not')\n",
    "            duplicated_image_phash_pairs.persist_add(hash_pair)\n",
    "            print('Duplicated')\n",
    "\n",
    "    def on_no (btn):\n",
    "        with output:\n",
    "            if hash_pair in duplicated_image_phash_pairs:\n",
    "                duplicated_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Duplicated')\n",
    "            not_duplicated_image_phash_pairs.persist_add(hash_pair)\n",
    "            print('Not')\n",
    "\n",
    "    def on_related (btn):\n",
    "        with output:\n",
    "            if hash_pair in not_duplicated_image_phash_pairs:\n",
    "                not_duplicated_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Not')\n",
    "            related_image_phash_pairs.persist_add(hash_pair)\n",
    "            print('Related')\n",
    "\n",
    "    def on_invalid_x (btn):\n",
    "        invalid_image_phashes.persist_add(phash_x)\n",
    "        with output:\n",
    "            print('Invalid X')\n",
    "\n",
    "    def on_invalid_y (btn):\n",
    "        invalid_image_phashes.persist_add(phash_y)\n",
    "        with output:\n",
    "            print('Invalid Y')\n",
    "\n",
    "    def on_reset (btn):\n",
    "        with output:\n",
    "            if hash_pair in duplicated_image_phash_pairs:\n",
    "                duplicated_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Duplicated')\n",
    "            if hash_pair in not_duplicated_image_phash_pairs:\n",
    "                not_duplicated_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Not')\n",
    "            if hash_pair in related_image_phash_pairs:\n",
    "                related_image_phash_pairs.persist_remove(hash_pair)\n",
    "                print('-Related')\n",
    "            if phash_x in invalid_image_phashes:\n",
    "                invalid_image_phashes.persist_remove(phash_x)\n",
    "                print('-Invalid X')\n",
    "            if phash_y in invalid_image_phashes:\n",
    "                invalid_image_phashes.persist_remove(phash_y)\n",
    "                print('-Invalid Y')\n",
    "            print('Reset')\n",
    "\n",
    "    yes_btn.on_click(on_yes)\n",
    "    no_btn.on_click(on_no)\n",
    "    related_btn.on_click(on_related)\n",
    "    invalid_x_btn.on_click(on_invalid_x)\n",
    "    invalid_y_btn.on_click(on_invalid_y)\n",
    "    reset_btn.on_click(on_reset)\n",
    "\n",
    "    if default == 'no':\n",
    "        on_no(None)\n",
    "    elif default == 'yes':\n",
    "        on_yes(None)\n",
    "\n",
    "    return HBox([VBox([yes_btn, no_btn, related_btn, invalid_x_btn, invalid_y_btn, reset_btn, output]),\n",
    "                 widgets.Image(value=open(image_x['file_path'], 'rb').read(), width=250, height=150),\n",
    "                 widgets.Image(value=open(image_y['file_path'], 'rb').read(), width=250, height=150)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_duplicates (threshold):\n",
    "    for i in range(distance.shape[0]):\n",
    "        for j in range(i):\n",
    "            if distance[i, j] <= threshold:\n",
    "                phash_pair = frozenset([imageDedup[i]['phash'], imageDedup[j]['phash']])\n",
    "                if (phash_pair not in auto_duplicated_image_phash_pairs and\n",
    "                    phash_pair not in duplicated_post_image_phash_pairs and\n",
    "                    phash_pair not in duplicated_image_phash_pairs and\n",
    "                    phash_pair not in not_duplicated_image_phash_pairs and\n",
    "                    phash_pair not in related_album_image_phash_pairs and\n",
    "                    phash_pair not in related_image_phash_pairs):\n",
    "                    yield (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdup = potential_duplicates(distance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StopIteration\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        next_pdup = next(pdup)\n",
    "    except StopIteration:\n",
    "        print('StopIteration')\n",
    "        break\n",
    "\n",
    "    idx_x, idx_y = next_pdup\n",
    "    image_x = imageDedup[idx_x]\n",
    "    image_y = imageDedup[idx_y]\n",
    "    print(f\"{idx_x} {idx_y} {distance[idx_x, idx_y]} {image_x['phash']} {image_y['phash']} {image_x['width']} {image_y['width']} {image_x['image_id']} {image_y['image_id']}\")\n",
    "    display(make_dedup_box(idx_x, idx_y, default=None if distance[idx_x, idx_y] < 6 else 'no'))\n",
    "    # display(make_dedup_box(idx_x, idx_y, default='yes' if distance[idx_x, idx_y] < 9 else 'no'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually check images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images with high variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interested_phashes = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def potential_duplicates_high (threshold):\n",
    "#     for i in range(distance.shape[0]):\n",
    "#         for j in range(i):\n",
    "#             if distance[i, j] >= threshold:\n",
    "#                 phash_pair = frozenset([imageDedup[i]['phash'], imageDedup[j]['phash']])\n",
    "#                 if (phash_pair in duplicated_image_phash_pairs):\n",
    "#                     interested_phashes.add(imageDedup[i]['phash'])\n",
    "#                     interested_phashes.add(imageDedup[j]['phash'])\n",
    "#                     yield (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pduph = potential_duplicates_high(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     try:\n",
    "#         next_pdup = next(pduph)\n",
    "#     except StopIteration:\n",
    "#         print('StopIteration')\n",
    "#         break\n",
    "\n",
    "#     idx_x, idx_y = next_pdup\n",
    "#     image_x = imageDedup[idx_x]\n",
    "#     image_y = imageDedup[idx_y]\n",
    "#     print(f\"{idx_x} {idx_y} {distance[idx_x, idx_y]} {image_x['phash']} {image_y['phash']} {image_x['width']} {image_y['width']} {image_x['image_id']} {image_y['image_id']}\")\n",
    "#     display(make_dedup_box(idx_x, idx_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_image_phashes = set(json.load(open('handmade/invalid_image_phashes.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examined_images = [\n",
    "#     'reddit/dataisugly/2o08rl_0', # manually downloaded\n",
    "#     'reddit/dataisugly/2nwubr_0', # manually downloaded\n",
    "#     'reddit/dataisugly/beivt8_0', # manually downloaded\n",
    "#     'reddit/dataisugly/683b4i_0', # manually downloaded\n",
    "#     'reddit/dataisugly/3zcw30_0', # manually downloaded\n",
    "#     'reddit/dataisugly/1oxrh5_0', # manually downloaded a higher resolution image\n",
    "#     'reddit/dataisugly/3or2g0_0', # manually downloaded\n",
    "#     'reddit/dataisugly/5iobqn_0', # manually downloaded\n",
    "#     'reddit/dataisugly/29fpuo_0', # manually downloaded\n",
    "#     'reddit/dataisugly/5xux1f_0', # manually downloaded\n",
    "#     'reddit/dataisugly/35lrw1_0', # manually downloaded\n",
    "#     'reddit/dataisugly/1bxhv2_0', # manually downloaded a higher resolution image\n",
    "#     'reddit/dataisugly/3peais_0', # manually downloaded\n",
    "#     'reddit/dataisugly/2vdk71_0', # manually downloaded\n",
    "#     'reddit/dataisugly/6b8w73_0', # manually downloaded\n",
    "#     'reddit/dataisugly/2w8pnr_0', # manually downloaded an image with more context\n",
    "#     'reddit/dataisugly/2dt19h_0', # manually downloaded\n",
    "#     'reddit/dataisugly/31tj8a_0', # manually downloaded\n",
    "#     'reddit/dataisugly/30smxr_0', # manually downloaded\n",
    "#     'reddit/dataisugly/30dbx6_0', # manually downloaded\n",
    "#     'reddit/dataisugly/561ytm_0', # manually downloaded\n",
    "#     'reddit/dataisugly/6q4tre_0', # manually downloaded\n",
    "#     'reddit/dataisugly/3icm4g_0', # manually downloaded\n",
    "#     'reddit/dataisugly/6z5v98_0', # manually downloaded\n",
    "#     'reddit/dataisugly/5fucjm_0', # manually downloaded\n",
    "#     'reddit/dataisugly/99bczz_0', # manually downloaded\n",
    "#     'reddit/dataisugly/2662wv_0', # manually downloaded\n",
    "#     'reddit/dataisugly/26otpi_0', # manually downloaded a higher resolution image\n",
    "#     'reddit/dataisugly/68scgb_0', # manually downloaded\n",
    "#     'reddit/dataisugly/et75qp_0', # manually downloaded\n",
    "#     'reddit/dataisugly/4c9zc1_0', # manually downloaded an image with more context\n",
    "#     'reddit/dataisugly/2525a5_0', # manually downloaded more images, but does not matched with the one with more context\n",
    "#     'reddit/dataisugly/2la7zt_0', # thumbnail alt\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalids = []\n",
    "# for h in invalid_image_phashes:\n",
    "#     invalid_images = [f for f in imagefiles.find({'phash': h})]\n",
    "#     if len(invalid_images) > 0:\n",
    "#         invalids.append(invalid_images[0])\n",
    "\n",
    "# display(Box([widgets.Image(value=open(i['file_path'], 'rb').read(), width=100, height=100) for i in invalids],\n",
    "#             layout=Layout(display='flex', flex_flow='row wrap')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_images = [[imageDedup[idx]['image_id'] for idx in c]\n",
    "                     for c in nx.components.connected_components(nx.Graph(related_distance <= 1))\n",
    "                     if len(c) > 1]\n",
    "len(related_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids in related_images:\n",
    "    for i in ids:\n",
    "        imageMeta = imageDedup[image_id_to_idx(i)]\n",
    "        ri = [r for r in set(imageMeta.get('related_images', []) + ids) if r != i]\n",
    "        imagededup.update_one({'image_id': i}, {'$set': {'related_images': ri}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding_image_phashes = PersistentSet.load_set(handmade_dir/'excluding_image_phashes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding_image_phashes.persist_add('c13e3ae10e70fd86')\n",
    "excluding_image_phashes.persist_add('fe81837a94e3807e')\n",
    "excluding_image_phashes.persist_add('af9da24292fae149')\n",
    "excluding_image_phashes.persist_add('ad87d2696738ca4c')\n",
    "excluding_image_phashes.persist_add('d25264dfa9659392')\n",
    "excluding_image_phashes.persist_add('964e3b3160e14f8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDedup ():\n",
    "    _attrs = [\n",
    "        'id',\n",
    "        'post_id',\n",
    "        'datetime',\n",
    "        'url',\n",
    "        'title',\n",
    "        'content',\n",
    "        'author',\n",
    "        'removed',\n",
    "        'ups',\n",
    "        'num_comments',\n",
    "        'external_link',\n",
    "        'source',\n",
    "        'source_platform',\n",
    "        'source_url',\n",
    "        'tags',\n",
    "        'labels',\n",
    "        'media_type',\n",
    "        'thumbnail_url',\n",
    "        'preview_url',\n",
    "        'external_link_url',\n",
    "        'archive_url',\n",
    "\n",
    "        'thumbnail',\n",
    "        'preview',\n",
    "        'external_link',\n",
    "        'archive',\n",
    "        'manual',\n",
    "\n",
    "        'image_id',\n",
    "        'short_image_id',\n",
    "        'album',\n",
    "        'index_in_album',\n",
    "        'image_type',\n",
    "        'file_path',\n",
    "        'ext',\n",
    "        'animated',\n",
    "        'size',\n",
    "        'width',\n",
    "        'height',\n",
    "        'pixels',\n",
    "        'image_order',\n",
    "        'ahash',\n",
    "        'phash',\n",
    "        'pshash',\n",
    "        'dhash',\n",
    "        'whash',\n",
    "\n",
    "        'duplicated_posts',\n",
    "        'related_images',\n",
    "        'duplicated_images',\n",
    "        'popularity_score'\n",
    "    ]\n",
    "\n",
    "    def __init__ (self, imageMetas=[]):\n",
    "        # print(imageMetas)\n",
    "        if len(imageMetas) == 0:\n",
    "            raise Exception('Empty imageFiles array.')\n",
    "\n",
    "        self._imageMetas = imageMetas\n",
    "        self._image_ids = [i['image_id'] for i in imageMetas]\n",
    "        self._image_order = sort_images(self._imageMetas)\n",
    "\n",
    "        self._post_ids = {i['post_id'] for i in imageMetas}\n",
    "        self._posts = [posts.find_one({'post_id': i}) for i in self._post_ids]\n",
    "        dpost = []\n",
    "        for p in self._posts:\n",
    "            if 'duplicated_posts' in p:\n",
    "                for i in p['duplicated_posts']:\n",
    "                    if i not in self._post_ids:\n",
    "                         dpost.append(posts.find_one({'post_id': i}))\n",
    "        self._posts += dpost\n",
    "        if None in self._posts:\n",
    "            print(self._post_ids)\n",
    "        self._post_order = sort_posts(self._posts)\n",
    "\n",
    "        for k, v in self.main_image.items():\n",
    "            if k in ['duplicated_posts', 'related_images']:\n",
    "                continue\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        for k, v in self.main_post.items():\n",
    "            if k in ['duplicated_posts', 'related_images']:\n",
    "                continue\n",
    "            if k in ['preview', 'thumbnail', 'external_link', 'archive', 'manual']:\n",
    "                setattr(self, f\"{k}_url\", v)\n",
    "            else:\n",
    "                setattr(self, k, v)\n",
    "\n",
    "    def digest (self):\n",
    "        return {a:getattr(self, a) for a in ImageDedup._attrs if hasattr(self, a)}\n",
    "\n",
    "    @property\n",
    "    def duplicated_posts (self):\n",
    "        post_ids = self._post_ids.union(*[set(p.get('duplicated_posts', [])) for p in self._posts])\n",
    "        return [i for i in post_ids if i != self.post_id]\n",
    "\n",
    "    @property\n",
    "    def duplicated_images (self):\n",
    "        return [i for i in self._image_ids if i != self.image_id]\n",
    "\n",
    "    @property\n",
    "    def related_images (self):\n",
    "        return [ri for i in self._imageMetas for ri in i.get('related_images', []) if ri != self.image_id]\n",
    "\n",
    "    @property\n",
    "    def main_post (self):\n",
    "#         if len(self._post_order) > 1 and self._post_order[0]['source_platform'] != 'reddit':\n",
    "#             print(f\"main post warning: {[p['post_id'] for p in self._post_order]}\")\n",
    "        return self._post_order[0]\n",
    "\n",
    "    @property\n",
    "    def popularity_score (self):\n",
    "        return sum([post_score(p) for p in self._posts if p['source'] == 'dataisugly'])\n",
    "\n",
    "    @property\n",
    "    def main_image (self):\n",
    "#         if len(self._image_order) > 1 and self._image_order[0]['source_platform'] != 'reddit':\n",
    "#             print(f\"main image warning: {[i['image_id'] for i in self._image_order]}\")\n",
    "        mi = [i for i in self._image_order if i['phash'] not in excluding_image_phashes][0]\n",
    "        return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_images = [list(set([imageDedup[idx]['image_id'] for idx in c]))\n",
    "                     for c in nx.components.connected_components(nx.Graph(distance <= 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageDedup[image_id_to_idx('reddit/AusFinance/fman6b_0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup_image (ids):\n",
    "    imagedd = ImageDedup([imageDedup[image_id_to_idx(i)] for i in set(ids)])\n",
    "    # if imagedd.main_post['source'] != 'dataisugly':\n",
    "        # print(f\"Image not from dataisugly: {imagedd.main_post['post_id']}\")\n",
    "    for i in imagedd.duplicated_images:\n",
    "        imagededup.delete_one({'image_id': i})\n",
    "    imagededup.replace_one({'image_id': imagedd.image_id}, imagedd.digest(), upsert=True)\n",
    "    return imagedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec2e148f5e64039ab70836aed84fc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8894.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imagedds = parallel(dedup_image, duplicated_images, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated_image_ids = [c\n",
    "#                      for c in nx.components.connected_components(nx.Graph(distance <= 1))\n",
    "#                      if len(c) > 1]\n",
    "# start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(duplicated_image_ids)\n",
    "# cnt = 0\n",
    "# end = start + 50\n",
    "# for idxs in duplicated_image_ids:\n",
    "# #     print(f\"{[imageDedup[i]['image_id'] for i in idxs]}\")\n",
    "# #     if len(idxs) == 2:\n",
    "#     if len(idxs) >= 4:\n",
    "#         if cnt >= start:\n",
    "#             print(*[imageDedup[i]['image_id'] for i in idxs])\n",
    "#             print(*[imageDedup[i]['phash'] for i in idxs])\n",
    "#             display(HBox([\n",
    "#                 widgets.Image(value=open(imageDedup[i]['file_path'], 'rb').read(), width=100, height=100)\n",
    "#                 for i in idxs]))\n",
    "#         cnt += 1\n",
    "#         if cnt >= end:\n",
    "#             print(end)\n",
    "#             start = end\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
