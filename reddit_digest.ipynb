{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lib.labels_from_tags import labels_from_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mongo = MongoClient('172.17.0.1', 27017)\n",
    "db = mongo['bad-vis']\n",
    "raw = db['reddit-merge']\n",
    "posts = db['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping, Sequence\n",
    "from collections import Counter\n",
    "\n",
    "# from https://stackoverflow.com/questions/51488240/python-get-json-keys-as-full-path\n",
    "def get_paths(source):\n",
    "    paths = []\n",
    "    if isinstance(source, MutableMapping):  # found a dict-like structure...\n",
    "        for k, v in source.items():  # iterate over it; Python 2.x: source.iteritems()\n",
    "            paths.append([k])  # add the current child path\n",
    "            paths += [[k] + x for x in get_paths(v)]  # get sub-paths, extend with the current\n",
    "    # else, check if a list-like structure, remove if you don't want list paths included\n",
    "    elif isinstance(source, Sequence) and not isinstance(source, str):\n",
    "        #                          Python 2.x: use basestring instead of str ^\n",
    "        for i, v in enumerate(source):\n",
    "            paths.append([i])\n",
    "            paths += [[i] + x for x in get_paths(v)]  # get sub-paths, extend with the current\n",
    "    return paths\n",
    "\n",
    "c = Counter([str(p) for s in raw.find() for p in get_paths(s)])\n",
    "with open('reddit_attrs.txt', 'w') as f:\n",
    "    f.write(str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Submission ():\n",
    "    _attrs = [\n",
    "        'id',\n",
    "        'post_id',\n",
    "        'datetime',\n",
    "        'url',\n",
    "        'title',\n",
    "        'content',\n",
    "        'author',\n",
    "        'thumbnail',\n",
    "        'preview',\n",
    "        'removed',\n",
    "        'ups',\n",
    "        'num_comments',\n",
    "        'external_link',\n",
    "        'source',\n",
    "        'source_url',\n",
    "        'duplicated_post',\n",
    "        'tags',\n",
    "        'media_type',\n",
    "        'labels'\n",
    "    ]\n",
    "\n",
    "    _video_type = {\n",
    "        'gfycat.com',\n",
    "        'streamable.com',\n",
    "        'vimeo.com',\n",
    "        'youtube.com'\n",
    "    }\n",
    "\n",
    "    def __init__ (self, s, duplicated_post=None):\n",
    "        self._s = s\n",
    "        self._duplicated_post = duplicated_post\n",
    "        self._subreddit = s['subreddit'] if type(s['subreddit']) == str else s['subreddit']['display_name']\n",
    "\n",
    "        self.id = s['id']\n",
    "        self.post_id = f'reddit/{self._subreddit}/{self.id}'\n",
    "        self.title = s['title']\n",
    "        self.content = s['selftext']\n",
    "        self.ups = s['ups']\n",
    "        self.num_comments = s['num_comments']\n",
    "        self.source = 'Reddit'\n",
    "        self.source_url = f'https://www.reddit.com/{s[\"subreddit_name_prefixed\"]}'\n",
    "\n",
    "        self._crosspost = Submission(s['crosspost_parent_list'][0], self.post_id) if 'crosspost_parent_list' in s and len(s['crosspost_parent_list']) > 0 else None\n",
    "\n",
    "    def digest (self):\n",
    "        return {a:getattr(self, a) for a in Submission._attrs}\n",
    "\n",
    "    @property\n",
    "    def datetime (self):\n",
    "        return datetime.fromtimestamp(self._s['created_utc']).isoformat()\n",
    "\n",
    "    @property\n",
    "    def url (self):\n",
    "        if 'permalink' in self._s:\n",
    "            if self._s['permalink'].startswith('/'):\n",
    "                return f'https://reddit.com{self._s[\"permalink\"]}'\n",
    "            else:\n",
    "                print(f'url: {self._s[\"permalink\"]}')\n",
    "                return self._s['permalink']\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    @property\n",
    "    def author (self):\n",
    "        if 'author' in self._s and self._s['author']:\n",
    "            return self._s['author'] if type(self._s['author']) == str else self._s['author']['name']\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    @property\n",
    "    def external_link (self):\n",
    "        if 'url' in self._s and self._s['url'] != self.url:\n",
    "            return self._s['url']\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    @property\n",
    "    def duplicated_post (self):\n",
    "        if self._duplicated_post:\n",
    "            return self._duplicated_post\n",
    "        if self._crosspost:\n",
    "            return self._crosspost.post_id\n",
    "        if 'viz.wtf' in self.external_link:\n",
    "            wtfviz_id = [t for t in self.external_link.split('/') if t.isdigit()]\n",
    "            return f'tumblr/wtf-viz/{wtfviz_id}'\n",
    "        return ''\n",
    "\n",
    "    @property\n",
    "    def tags (self):\n",
    "        return [self._s['link_flair_text']] if 'link_flair_text' in self._s and self._s['link_flair_text'] else []\n",
    "\n",
    "    @property\n",
    "    def labels (self):\n",
    "        return {\n",
    "            'auto': labels_from_tags(self.tags)\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def media_type (self):\n",
    "        if 'is_video' in self._s and self._s['is_video']:\n",
    "            return 'video'\n",
    "        if 'media' in self._s and self._s['media'] and 'type' in self._s['media']:\n",
    "            if self._s['media']['type'] in Submission._video_type:\n",
    "                return 'video'\n",
    "        if self.preview['url']:\n",
    "            return 'image'\n",
    "        return 'text'\n",
    "\n",
    "    @property\n",
    "    def preview (self):\n",
    "        try:\n",
    "            if 'preview' in self._s:\n",
    "                return {\n",
    "                    'url': self._s['preview']['images'][0]['source']['url'],\n",
    "                    'width': self._s['preview']['images'][0]['source']['width'],\n",
    "                    'height': self._s['preview']['images'][0]['source']['height']\n",
    "                }\n",
    "            elif 'url' in self._s:\n",
    "#                     print(f'Reddit submission preview digest no preview but url: {self._s[\"id\"]} {self.url}')\n",
    "                return {\n",
    "                    'url': '',\n",
    "                    'width': 0,\n",
    "                    'height': 0\n",
    "                }\n",
    "            else:\n",
    "#                     print(f'Reddit submission preview digest no preview nor url: {self._s[\"id\"]}')\n",
    "                return {\n",
    "                    'url': '',\n",
    "                    'width': 0,\n",
    "                    'height': 0\n",
    "                }\n",
    "        except Exception as inst:\n",
    "            print(f'Reddit submission preview digest error: {inst}')\n",
    "            print(f'Reddit submission: {self._s[\"id\"]} {self.url}')\n",
    "            return {\n",
    "                'url': '',\n",
    "                'width': 0,\n",
    "                'height': 0\n",
    "            }\n",
    "\n",
    "    @property\n",
    "    def thumbnail (self):\n",
    "        try:\n",
    "            if 'thumbnail' in self._s:\n",
    "                if not self._s['thumbnail'].startswith('http'):\n",
    "                    if not (self._s['thumbnail'] == 'default' or self._s['thumbnail'] == 'self' or self._s['thumbnail'] == 'spoiler' or self._s['thumbnail'] == 'nsfw' or self._s['thumbnail'] == 'image'):\n",
    "                        print(f\"Reddit submission thumbnail invalid url: {self.id} {self._s['thumbnail']}\")\n",
    "                    return {\n",
    "                        'url': '',\n",
    "                        'width': 0,\n",
    "                        'height': 0\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        'url': self._s['thumbnail'],\n",
    "                        'width': self._s['thumbnail_width'],\n",
    "                        'height': self._s['thumbnail_height']\n",
    "                    }\n",
    "            elif 'preview' in self._s:\n",
    "                return {\n",
    "                    'url': self._s['preview']['images'][0]['resolutions'][0]['url'],\n",
    "                    'width': self._s['preview']['images'][0]['resolutions'][0]['width'],\n",
    "                    'height': self._s['preview']['images'][0]['resolutions'][0]['height']\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'url': '',\n",
    "                    'width': 0,\n",
    "                    'height': 0\n",
    "                }\n",
    "        except Exception as inst:\n",
    "            print(f'Reddit submission thumbnail digest error: {inst}')\n",
    "            print(f'Reddit submission: {self._s[\"id\"]} {self.url}')\n",
    "            return {\n",
    "                'url': '',\n",
    "                'width': 0,\n",
    "                'height': 0\n",
    "            }\n",
    "\n",
    "    @property\n",
    "    def removed (self):\n",
    "        return '' if not self._s['removed_by_category'] else self._s['removed_by_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def digest_all_submissions ():\n",
    "    for s in tqdm(raw.find()):\n",
    "        submission = Submission(s)\n",
    "        posts.replace_one({'post_id': submission.post_id}, submission.digest(), upsert=True)\n",
    "        if submission._crosspost:\n",
    "            posts.replace_one({'post_id': submission._crosspost.post_id}, submission._crosspost.digest(), upsert=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198b23b2013b4a889e3da17a491d7b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "digest_all_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5e36b8a188ff1ac1a2751292'),\n",
       " 'id': '4f927p',\n",
       " 'post_id': 'reddit/dataisugly/4f927p',\n",
       " 'datetime': '2016-04-17T23:25:13',\n",
       " 'url': 'https://reddit.com/r/dataisugly/comments/4f927p/the_truth_about_abuse/',\n",
       " 'title': 'The Truth about Abuse',\n",
       " 'content': '[deleted]',\n",
       " 'author': '',\n",
       " 'thumbnail': {'url': '', 'width': 0, 'height': 0},\n",
       " 'preview': {'url': '', 'width': 0, 'height': 0},\n",
       " 'removed': '',\n",
       " 'ups': 0,\n",
       " 'num_comments': 0,\n",
       " 'external_link': 'http://imgur.com/(null)',\n",
       " 'source': 'Reddit',\n",
       " 'source_url': 'https://www.reddit.com/r/dataisugly',\n",
       " 'duplicated_post': '',\n",
       " 'tags': [],\n",
       " 'media_type': 'text',\n",
       " 'labels': {'auto': []}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.find_one({'id': '4f927p'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x7f15072a7ec8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.delete_one({'id': '4f927p'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
